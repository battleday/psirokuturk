{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffb52193",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, sys, gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.tri as tri\n",
    "from collections import Counter\n",
    "from scipy.special import factorial\n",
    "import itertools\n",
    "from math import comb\n",
    "from scipy.stats import chi2\n",
    "import dataframe_image as dfi\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd3fc844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'processed_data.p', 'participants.csv', 'html-button-response-filtered.csv', 'html-button-response.csv', 'survey-multi-select.csv', 'processed_data_summary.p', 'html-keyboard-response.csv']\n",
      "0:05:05.133333\n",
      "['00:02:22', '00:02:32', '00:02:42', '00:02:58', '00:03:00', '00:03:06', '00:03:06', '00:03:11', '00:03:25', '00:03:29', '00:03:32', '00:03:38', '00:03:47', '00:03:55', '00:04:02', '00:04:10', '00:04:22', '00:04:27', '00:04:34', '00:05:18', '00:05:20', '00:05:28', '00:05:30', '00:05:34', '00:05:52', '00:05:56', '00:06:34', '00:07:53', '00:10:09', '00:22:42']\n"
     ]
    }
   ],
   "source": [
    "version = '1.0'\n",
    "load_dir = '../data/human/{}'.format(version)\n",
    "save_dir = load_dir\n",
    "print(os.listdir(load_dir))\n",
    "times = ['00:10:09', '00:07:53', '00:04:34', '00:03:06', '00:04:27',\n",
    "'00:05:30', '00:02:22', '00:03:47', '00:03:29', '00:03:25',\n",
    "'00:03:38', '00:05:20', '00:05:34', '00:03:00', '00:03:06',\n",
    "'00:22:42', '00:02:58', '00:02:42', '00:04:10', '00:05:28',\n",
    "'00:05:18', '00:04:22', '00:02:32', '00:03:11', '00:03:55',\n",
    "'00:04:02', '00:06:34', '00:03:32', '00:05:52', '00:05:56']\n",
    "\n",
    "print((str(timedelta(seconds=sum(map(lambda f: int(f[0])*3600 + int(f[1])*60 + int(f[2]), map(lambda f: f.split(':'), times)))/len(times)))))\n",
    "print(sorted(times))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c665db",
   "metadata": {},
   "source": [
    "# Data analysis\n",
    "In this script, we apply classical and Bayesian approaches to determine whether the data provide significant evidence of deviations from independence between features and relations. We will either focus on the strong or weak MAX effect, or MAX and MIN effects together (both of these represent deviations). \n",
    "\n",
    "The data are presented below. (D-B) - (C-A) positive represents weak support for MAX, and Max indicates whether strong support was also found. Strong support for a participant implies weak support. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3be70de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N is 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0209/141442.470036:ERROR:xattr.cc(63)] setxattr org.chromium.crashpad.database.initialized on file /var/folders/z3/65sxpv5n3csdhfzm0ysx30940000gp/T/: Operation not permitted (1)\n",
      "[0209/141442.471230:ERROR:file_io.cc(94)] ReadExactly: expected 8, observed 0\n",
      "[0209/141442.472448:ERROR:xattr.cc(63)] setxattr org.chromium.crashpad.database.initialized on file /var/folders/z3/65sxpv5n3csdhfzm0ysx30940000gp/T/: Operation not permitted (1)\n",
      "[0209/141443.123603:INFO:headless_shell.cc(659)] Written to file /var/folders/z3/65sxpv5n3csdhfzm0ysx30940000gp/T/tmp1uteyp9e/temp.png.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Ours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>5.8</td>\n",
       "      <td>5.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>3.4</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>5.2</td>\n",
       "      <td>4.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>3.6</td>\n",
       "      <td>2.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(D-B)-(C-A)</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_max</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_min</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>29.0</td>\n",
       "      <td>28.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_ind</th>\n",
       "      <td>14.0</td>\n",
       "      <td>27.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Original   Ours\n",
       "A                 5.8   5.43\n",
       "B                 3.4   1.61\n",
       "C                 5.2   4.59\n",
       "D                 3.6   2.16\n",
       "(D-B)-(C-A)       0.8   1.39\n",
       "N_max            10.0   1.00\n",
       "N_min             5.0   0.00\n",
       "N                29.0  28.00\n",
       "N_ind            14.0  27.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ours</th>\n",
       "      <th>Original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>5.43</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>1.61</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>4.59</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>2.16</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(D-B)-(C-A)</th>\n",
       "      <td>1.39</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>28.00</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_ind</th>\n",
       "      <td>27.00</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Ours  Original\n",
       "A             5.43       6.4\n",
       "B             1.61       3.1\n",
       "C             4.59       5.8\n",
       "D             2.16       3.6\n",
       "(D-B)-(C-A)   1.39       1.1\n",
       "N_max         1.00      14.0\n",
       "N_min         0.00       3.0\n",
       "N            28.00      29.0\n",
       "N_ind        27.00      12.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fullDataDF = pd.read_pickle('{}/processed_data.p'.format(load_dir))\n",
    "N = len(fullDataDF)\n",
    "print('N is {}'.format(N))\n",
    "#display(fullDataDF)\n",
    "\n",
    "summary = pd.read_pickle('{}/processed_data_summary.p'.format(load_dir))\n",
    "\n",
    "summary.loc['N_ind'] = summary.loc[\"N\"] - summary.loc[\"N_max\"] - summary.loc[\"N_min\"]\n",
    "dfi.export(summary, '{}/pilot_results.png'.format(save_dir))\n",
    "display(summary.round(2))\n",
    "summary.drop(labels=[\"Original\"], axis=\"columns\", inplace=True)\n",
    "summary[\"Original\"] = [6.4, 3.1, 5.8, 3.6, 1.1, 14, 3, 29, 12]\n",
    "display(summary.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cd2f5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Counts')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, 2, sharey=True, figsize=(10, 2))\n",
    "ax[0].bar(['MAX', 'IND', 'MIN'], [summary[\"Ours\"].loc[\"N_max\"], summary[\"Ours\"].loc[\"N_ind\"], summary[\"Ours\"].loc[\"N_min\"]])\n",
    "ax[1].bar(['MAX', 'IND', 'MIN'], [summary[\"Original\"].loc[\"N_max\"], summary[\"Original\"].loc[\"N_ind\"], summary[\"Original\"].loc[\"N_min\"]])\n",
    "ax[0].set_title('Ours')\n",
    "ax[1].set_title('Original')\n",
    "ax[0].set_ylabel('Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "240035a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dirichlet plotting functions; from here http://blog.bogatron.net/blog/2014/02/02/visualizing-dirichlet-distributions/\n",
    "\n",
    "class Dirichlet(object):\n",
    "    def __init__(self, alpha):\n",
    "        from math import gamma\n",
    "        from operator import mul\n",
    "        self._alpha = np.array(alpha)\n",
    "        self._coef = gamma(np.sum(self._alpha)) / \\\n",
    "                           np.multiply.reduce([gamma(a) for a in self._alpha])\n",
    "    def pdf(self, x):\n",
    "        '''Returns pdf value for `x`.'''\n",
    "        from operator import mul\n",
    "        return self._coef * np.multiply.reduce([xx ** (aa - 1)\n",
    "                                               for (xx, aa)in zip(x, self._alpha)])\n",
    "def xy2bc(xy, tol=1.e-4):\n",
    "    '''Converts 2D Cartesian coordinates to barycentric.'''\n",
    "    coords = np.array([tri_area(xy, p) for p in pairs]) / AREA\n",
    "    return np.clip(coords, tol, 1.0 - tol)\n",
    "\n",
    "def draw_pdf_contours(ax, dist, nlevels=200, subdiv=8, **kwargs):\n",
    "    import math\n",
    "\n",
    "    refiner = tri.UniformTriRefiner(triangle)\n",
    "    trimesh = refiner.refine_triangulation(subdiv=subdiv)\n",
    "    pvals = [dist.pdf(xy2bc(xy)) for xy in zip(trimesh.x, trimesh.y)]\n",
    "\n",
    "    ax.tricontourf(trimesh, pvals, nlevels, cmap='jet', **kwargs)\n",
    "    ax.axis('equal')\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 0.75**0.5)\n",
    "    ax.axis('off')\n",
    "    \n",
    "corners = np.array([[0, 0], [1, 0], [0.5, 0.75**0.5]])\n",
    "AREA = 0.5 * 1 * 0.75**0.5\n",
    "triangle = tri.Triangulation(corners[:, 0], corners[:, 1])\n",
    "refiner = tri.UniformTriRefiner(triangle)\n",
    "trimesh = refiner.refine_triangulation(subdiv=4)\n",
    "# For each corner of the triangle, the pair of other corners\n",
    "pairs = [corners[np.roll(range(3), -i)[1:]] for i in range(3)]\n",
    "# The area of the triangle formed by point xy and another pair or points\n",
    "tri_area = lambda xy, pair: 0.5 * np.linalg.norm(np.cross(*(pair - xy)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543f5be5",
   "metadata": {},
   "source": [
    "## Strong evidence 1: MAX vs MIN\n",
    "Strong evidence to support dependence of features and relations comes from participants acting in logical consistency with the MAX or MIN effects.\n",
    "\n",
    "MAX: SIM(D, T) > SIM(B, T) & SIM(A, T) > SIM (C, T) (Both trials)\n",
    "\n",
    "MIN: SIM(D, T) < SIM(B, T) & SIM(A, T) < SIM (C, T) (Both trials)\n",
    "\n",
    "The authors of the original work assess the strong effect as the number of participants who behave consistently with the MAX strategy over those behaving consistently with the MIN. This is a simple binomial test, with the assumption that random behaviour would lead to equal probabilities.\n",
    "\n",
    "The (one-tailed) exact binomial test is straightforward to calculate. Recall that the probability of $h$ heads under the binomial distribution is:\n",
    "\n",
    "$$\n",
    "p(x=h) = {N \\choose h}p^h(1-p)^{N-h}\n",
    "$$\n",
    "\n",
    "The binomial test then counts exactly how many outcomes are less or equally probable than ours under a null model. Setting our null model to $\\pi_0=(1-\\pi_0)=\\frac{1}{2}$:\n",
    "\n",
    "$$\n",
    "p = \\sum_{i=0}^h{N_{Max/Min} \\choose i}\\pi_0^i(1-\\pi_0)^{N_{Max/Min}-i},\n",
    "$$\n",
    "\n",
    "Where $N_{Max/Min}$ is the number of participants showing one of the effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c3ca093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0\n",
      "15.0\n",
      "Binomial test for original data is 0.15087890625; reported in study was 0.0156\n",
      "1.0\n",
      "1.0\n",
      "Binomial test for our data is 0.5\n"
     ]
    }
   ],
   "source": [
    "def binomial_probability(h, p, N):\n",
    "    return comb(int(N), int(h)) * (p**h) * ((1-p)**(N-h))\n",
    "\n",
    "def binomial_test(h, p, N_m):\n",
    "    p_val = 0\n",
    "    for i in np.arange(h, N_m+1): # number of maxes \"heads\"\n",
    "        p_val += binomial_probability(i, p, N_m)\n",
    "    return p_val\n",
    "\n",
    "originalH = summary[\"Original\"].loc[\"N_max\"]\n",
    "originalNM = originalH + summary[\"Original\"].loc[\"N_min\"]\n",
    "\n",
    "ourH = summary[\"Ours\"].loc[\"N_max\"]\n",
    "ourNM = ourH + summary[\"Ours\"].loc[\"N_min\"]\n",
    "\n",
    "print(\"Binomial test for original data is {}; reported in study was 0.0156\".format(binomial_test(originalH,\n",
    "                                                                                                 0.5,\n",
    "                                                                                                 originalNM\n",
    "                                                                                                )))\n",
    "\n",
    "print(\"Binomial test for our data is {}\".format(binomial_test(ourH,\n",
    "                                                              0.5,\n",
    "                                                              ourNM\n",
    "                                                             )))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0160c379",
   "metadata": {},
   "source": [
    "## Strong evidence 2: Distribution of behaviours\n",
    "Strong evidence to support dependence of features and relations comes from participants acting in logical consistency with the MAX or MIN effects.\n",
    "\n",
    "MAX: SIM(D, T) > SIM(B, T) & SIM(A, T) > SIM (C, T) (Both trials)\n",
    "\n",
    "MIN: SIM(D, T) < SIM(B, T) & SIM(A, T) < SIM (C, T) (Both trials)\n",
    "\n",
    "The authors of the original work offer another assessment: the proportion\n",
    "\n",
    "We can think about modeling this as a multinomial distribution, where we have N observations and three categories (MAX, INDEP, MIN).\n",
    "\n",
    "Recall that the probability of a count vector under the multinomial distribution is:\n",
    "$$\n",
    "p({\\bf x}) = N!\\prod_{i=1}^k\\frac{\\pi_i^k}{x_i!}.\n",
    "$$\n",
    "\n",
    "The first question we can ask, is are there significantly more MAX and MIN responses than would be expected by chance? We can view \"by chance\" as meaning one of two things:\n",
    "\n",
    "<ol>\n",
    "    <li>Each guess is a chance event (uniform over 1-9) </li>\n",
    "    <li>Each behaviour is a chance event (MAX, IND, MIN) </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4db72e4",
   "metadata": {},
   "source": [
    "### Frequentist analysis\n",
    "The basis of frequentist analysis will be to propose hypotheses in the form of parameters for the multinomial distribution, and test whether our data deviates significantly from these. We have the following hypotheses to test:\n",
    "\n",
    "<ol>\n",
    "    <li>The result of random guessing, uniform over the similarity ratings for each pair; </li>\n",
    "    <li>The result of making judgements in accordance with feature-relation independence, smoothed (Laplace);</li>\n",
    "    <li>As above, with free noise parameter (Dirichlet($\\alpha, 1-2*\\alpha, \\alpha$)); </li>\n",
    "    <li>The MLE parameters from the original trial;</li>\n",
    "    <li>The MLE parameters;</li>\n",
    "    <li>The posterior mode parameters (Dirichlet(1, 1, 1) as prior.)</li>\n",
    "</ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f8fd6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulations = 100\n",
    "\n",
    "def random_guess_distribution(N):\n",
    "    \"\"\" This assumes people are guessing uniformly over 1-9 twice for each (target, base) pair.\"\"\"\n",
    "    results = {'MIN': 0, 'MAX': 0, 'IND': 0}\n",
    "    \n",
    "    for i in range(N):\n",
    "        # average of two guesses\n",
    "        guesses = np.mean(np.random.randint(low=0, high=10, size=(2, 4)), axis=0)\n",
    "        \n",
    "        if (guesses[3] - guesses[1] > 0) & (guesses[2] - guesses[0] < 0):\n",
    "            results['MAX'] += 1\n",
    "        elif (guesses[3] - guesses[1] < 0) & (guesses[2] - guesses[0] > 0):\n",
    "            results['MIN'] += 1\n",
    "        else:\n",
    "            results['IND'] += 1\n",
    "        \n",
    "    return results\n",
    "\n",
    "master_results = {'MIN': 0, 'MAX': 0, 'IND': 0}\n",
    "for run in range(simulations):\n",
    "    results = random_guess_distribution(N)\n",
    "    master_results = Counter(master_results) + Counter(results)\n",
    "master_results = {k: v / simulations for k, v in master_results.items()}\n",
    "\n",
    "fig, ax = plt.subplots(2, 4, sharey=True, figsize=(15, 4))\n",
    "ax[0][0].set_title('Ours')\n",
    "ax[0][0].bar(['MAX', 'IND', 'MIN'], [summary[\"Ours\"].loc[\"N_max\"], summary[\"Ours\"].loc[\"N_ind\"], summary[\"Ours\"].loc[\"N_min\"]])\n",
    "\n",
    "ax[0][1].set_title('Random guessing')\n",
    "ax[0][1].bar(['MAX', 'IND', 'MIN'], [master_results['MAX'], master_results['IND'], master_results['MIN']])\n",
    "\n",
    "ax[0][2].set_title('Feature-relation independence')\n",
    "ax[0][2].bar(['MAX', 'IND', 'MIN'], [1, N-2, 1])\n",
    "\n",
    "ax[0][3].set_title('Original')\n",
    "ax[0][3].bar(['MAX', 'IND', 'MIN'], [summary[\"Original\"].loc[\"N_max\"], summary[\"Original\"].loc[\"N_ind\"], summary[\"Original\"].loc[\"N_min\"]])\n",
    "\n",
    "for axs in ax[0]:\n",
    "    axs.set_xticks([])\n",
    "\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "ax[0][0].set_ylabel('Counts')\n",
    "ax[1][0].set_ylabel('Counts')\n",
    "\n",
    "ax[1][0].set_title('Alpha = 2')\n",
    "ax[1][0].bar(['MAX', 'IND', 'MIN'], [2, N-2, 2])\n",
    "\n",
    "ax[1][1].set_title('Alpha = 4')\n",
    "ax[1][1].bar(['MAX', 'IND', 'MIN'], [4, N-8, 4])\n",
    "\n",
    "ax[1][2].set_title('Alpha = 6')\n",
    "ax[1][2].bar(['MAX', 'IND', 'MIN'], [6, N-12, 6])\n",
    "\n",
    "ax[1][3].set_title('Random Behaviour')\n",
    "ax[1][3].bar(['MAX', 'IND', 'MIN'], [10, 10, 10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b6bf2d",
   "metadata": {},
   "source": [
    "#### Exact multinomial test\n",
    "We can use the exact multinomial test to give a p-value for the data under each of these models. This is the \"test of the null hypothesis that parameters of a multinomial distribution equal specified values.\" (Wikipedia)\n",
    "\n",
    "Under a given model ($\\theta = \\{\\pi_1, \\pi_2, \\pi_3\\}; \\sum_i\\pi_i = 1, \\forall i, \\pi_i > 0.$), the probability of our count vector can be calculated as follows:\n",
    "\n",
    "$$\n",
    "p({\\bf x}_0) = N!\\prod_{i=1}^k\\frac{\\pi_i^k}{x_i!}.\n",
    "$$\n",
    "\n",
    "We are interested in \"the probability of occurence of dataset observed, or less likely than that observed, if H0 true\". This can be calculated as:\n",
    "\n",
    "$$\n",
    "p_{sig} = \\sum_{{\\bf y}: p({\\bf y})\\le p({\\bf x}_0)}p({\\bf y})\n",
    "$$\n",
    "\n",
    "The computationally exacting part of this test is to \"figure out all the possible permutations in the values of each level that would be even less probable than the values in the sample.\" (https://rinterested.github.io/statistics/multinomial_exact.html)\n",
    "\n",
    "The number of possible count vectors is ${N+k-1 \\choose k-1}$. With $N\\approx30$, this is around 400 vectors; we can give it a go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee80ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomial_probability(counts, params):\n",
    "    k = len(counts)\n",
    "    N = sum(counts)\n",
    "    return factorial(N) * np.prod(params**counts / factorial(counts))\n",
    "\n",
    "testCounts = np.array([3, 2, 1])\n",
    "testParams = np.array([0.2, 0.7, 0.1])\n",
    "print(60*0.0008*0.49)\n",
    "print(multinomial_probability(testCounts, testParams))\n",
    "\n",
    "def generate_vectors(N, k):\n",
    "    \"\"\"A function that generates all possible count vectors. \n",
    "    This is the same as all ways of throwing N balls in k bins\"\"\"\n",
    "    masks = np.identity(k, dtype=int)\n",
    "    return itertools.combinations_with_replacement(masks, N)\n",
    "\n",
    "o = generate_vectors(4, 2)\n",
    "print([sum(c) for c in o])\n",
    "\n",
    "def exact_multinomial_test(counts, params, upper_limit = 10**10):\n",
    "    \"\"\"Takes observed counts, model params, and iterator over all possible count vectors.\n",
    "    Returns proportion of those vectors that are less probable; p-value.\"\"\"\n",
    "    N = int(sum(counts))\n",
    "    k = int(len(counts))\n",
    "\n",
    "    p_val = 0\n",
    "    prob_to_beat = multinomial_probability(counts, params)\n",
    "    combinations = comb(N+k-1, k-1)\n",
    "    if combinations > upper_limit:\n",
    "        print(\"not running {} combinations\".format(combinations))\n",
    "        return\n",
    "    else:\n",
    "        print(\"Running with {} combinations\".format(combinations))\n",
    "    \n",
    "    vector_iterator = generate_vectors(N, k)\n",
    "    \n",
    "    for c in vector_iterator:\n",
    "        tempCounts = sum(c)\n",
    "        prob_temp = multinomial_probability(tempCounts, params)\n",
    "        \n",
    "        if prob_temp <= prob_to_beat:\n",
    "            p_val += prob_temp\n",
    "        \n",
    "    return p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f28534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all models and test data against them\n",
    "print(N)\n",
    "print(comb(N+2, 2))\n",
    "counts = np.array([summary[\"Ours\"].loc[\"N_max\"], summary[\"Ours\"].loc[\"N_ind\"], summary[\"Ours\"].loc[\"N_min\"]])\n",
    "\n",
    "MLE = counts / N\n",
    "\n",
    "randomGuessingMC = np.array([master_results['MAX'], master_results['IND'], master_results['MIN']]) / N\n",
    "independenceLaplace = np.array([1, N-2, 1]) / N\n",
    "originalMLE = np.array([summary[\"Original\"].loc[\"N_max\"], summary[\"Original\"].loc[\"N_ind\"], summary[\"Original\"].loc[\"N_min\"]]) / N\n",
    "alpha2Model = np.array([2, N-4, 2]) / N\n",
    "alpha4Model = np.array([4, N-8, 4]) / N\n",
    "alpha6Model = np.array([6, N-12, 6]) / N\n",
    "randomBehaviour = np.array([1/3, 1/3, 1/3])\n",
    "\n",
    "models = {'Random Guessing': randomGuessingMC, \"IND Laplace\":independenceLaplace,\n",
    "         'MLE': MLE, 'Original MLE': originalMLE,\n",
    "         \"alpha = 2\": alpha2Model, \"alpha4Model\": alpha4Model, \"alpha6Model\": alpha6Model,\n",
    "         \"Random Behaviour\": randomBehaviour}\n",
    "\n",
    "for k, v in models.items():\n",
    "    print()\n",
    "    print(k)\n",
    "    print(v)\n",
    "    p_val_temp = exact_multinomial_test(counts, v)\n",
    "    print(\"p value is {}\".format(p_val_temp))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1dfeca",
   "metadata": {},
   "source": [
    "#### Likelihood ratio test\n",
    "\"An alternative hypothesis can be defined under which each value $\\pi_i$ is replaced by the MLE\" (Wikipedia):\n",
    "\n",
    "$$\n",
    "\\hat{\\pi}_i := \\frac{x_i}{N}\\\\\n",
    "p({\\bf x})_A = N! \\prod \\frac{\\hat{\\pi}_i^{x_i}}{x_i!}\n",
    "$$\n",
    "\n",
    "\"The natural logarithm of likelihood ratio between these probabilities is a statistic for the likelihood ratio test\":\n",
    "\n",
    "$$\n",
    "-2\\ln([\\mathcal{L}\\mathcal{R}]) = -2 \\sum_{i=1}^k x_i \\ln \\frac{\\pi_i}{\\hat{\\pi}_i}\n",
    "$$\n",
    "\n",
    "The constant factor is to make statistic asymptotically Chi-Squared, for convenience. We can then calculate the tail area probability by $1-CDF(\\text{LRT statistic}, k-1)$. The MLE for the multinomial has k-1 degrees of freedom because of the sum to one constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fac715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRT_multinomial(counts, probs1, MLE):\n",
    "    ratio = probs1 / MLE\n",
    "    print(ratio)\n",
    "    return -2*(np.sum(counts * np.log(ratio)))\n",
    "\n",
    "for k, v in models.items():\n",
    "    print()\n",
    "    print(k)\n",
    "    print(v)\n",
    "    chi = LRT_multinomial(counts, v, MLE)\n",
    "    print(\"Chi sum value is {}\".format(chi))\n",
    "    \n",
    "    p_val = 1 - chi2.cdf(chi, 2)\n",
    "    print(\"Approximate p value is {}\".format(p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c54a07c",
   "metadata": {},
   "source": [
    "#### More realistic null model\n",
    "Really, the model we are interested in testing our data against is that some combination of people guess, and some follow feature-relation independence (our current model's prediction). This can be thought of in a couple of ways, but the easiest analysis is in the frequentist setting. Here, a noise parameter, $\\alpha$, can be used to interpolate between these two models, giving a one-parameter model that would be contained within the parameter space of our full MLE model.\n",
    "\n",
    "That is, we model the data using the following multinomial distribution (with $c$ as a normalizing constant):\n",
    "\n",
    "$$\n",
    "p({\\bf x}) = c\\cdot\\alpha^{x_1}\\cdot(1-2\\cdot\\alpha)^{x_2}\\cdot\\alpha^{x_3} \n",
    "$$\n",
    "\n",
    "We can derive the MLE for $\\alpha$ as follows. Taking logs and dropping constants, the expression above becomes:\n",
    "\n",
    "$$\n",
    "\\log(p({\\bf x})) = (x_1+x_3)\\cdot\\log\\alpha + x_2\\log(1-2\\cdot\\alpha) \n",
    "$$\n",
    "\n",
    "Taking derviatives, we obtain:\n",
    "\n",
    "$$\n",
    "\\frac{d}{d \\alpha}\\log(p({\\bf x})) = \\frac{x_1+x_3}{\\alpha} + \\frac{x_2}{(1-2\\cdot\\alpha)} \n",
    "$$\n",
    "\n",
    "We can set this to zero, and rearrange to find any maxima:\n",
    "\n",
    "$$\n",
    "x_2\\cdot\\alpha  = (x_1+x_3)\\cdot(1-2\\cdot\\alpha) = x_1\\cdot(1-2\\cdot\\alpha) + x_3\\cdot(1-2\\cdot\\alpha) = x_1 - 2\\cdot\\alpha \\cdot x_1 + x_3 -2\\cdot\\alpha\\cdot x_3\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\alpha \\cdot (x_2 + 2x_1 + 2x_3) =  x_1+x_3\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\alpha = \\frac{x_1+x_3}{x_2 + 2x_1 + 2x_3},\n",
    "$$\n",
    "\n",
    "which makes intuitive sense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52d0da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_MLE(x_1, x_2, x_3):\n",
    "    return (x_1 + x_3) / (x_2 + 2*x_1 + 2*x_3)\n",
    "\n",
    "alpha = find_MLE(summary[\"Ours\"].loc[\"N_max\"], summary[\"Ours\"].loc[\"N_ind\"], summary[\"Ours\"].loc[\"N_min\"])\n",
    "alpha_M = alpha * N\n",
    "alpha_I = (1-2*alpha)*N\n",
    "alpha_m = alpha_M\n",
    "alphaModel = [alpha, 1-2*alpha, alpha]\n",
    "print('MLE of alpha is: {}'.format(alpha))\n",
    "print('P-value is {}'.format(exact_multinomial_test(counts, alphaModel)))\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, sharey=True, figsize=(15, 4))\n",
    "ax[0].set_title('Ours')\n",
    "ax[0].bar(['MAX', 'IND', 'MIN'], [summary[\"Ours\"].loc[\"N_max\"], summary[\"Ours\"].loc[\"N_ind\"], summary[\"Ours\"].loc[\"N_min\"]])\n",
    "\n",
    "ax[1].set_title('Random guessing')\n",
    "ax[1].bar(['MAX', 'IND', 'MIN'], [master_results['MAX'], master_results['IND'], master_results['MIN']])\n",
    "\n",
    "ax[2].set_title('Feature-relation independence')\n",
    "ax[2].bar(['MAX', 'IND', 'MIN'], [0, N, 0])\n",
    "\n",
    "ax[3].set_title('MLE alpha')\n",
    "ax[3].bar(['MAX', 'IND', 'MIN'], [alpha_M, alpha_I, alpha_m])\n",
    "\n",
    "ax[0].set_ylabel('Counts')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247c1773",
   "metadata": {},
   "source": [
    "### Bayesian analysis\n",
    "In the Bayesian setting, a basic null model for our data is to assume that all N observations come from the independence class, and incorporate our uncertainty in a uniform (Dirichlet) prior. This gives the following posterior.\n",
    "\n",
    "$\\theta^{null} \\, \\sim \\, \\text{Dirichlet}(1, N+1, 1).$\n",
    "\n",
    "There are a number of ways we could go about testing whether our data deviate from the numbers expected under a null model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e78b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = np.array([1, 1, 1])\n",
    "null = np.array([0, N, 0]) + prior\n",
    "actual = np.array([summary[\"Ours\"].loc[\"N_max\"], \n",
    "                  summary[\"Ours\"].loc[\"N_ind\"], summary[\"Ours\"].loc[\"N_max\"]]) + prior\n",
    "previous = np.array([summary[\"Original\"].loc[\"N_max\"], \n",
    "                     summary[\"Original\"].loc[\"N_ind\"], summary[\"Original\"].loc[\"N_max\"]])\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize = (15, 5))\n",
    "draw_pdf_contours(ax[0], Dirichlet(prior))\n",
    "draw_pdf_contours(ax[1], Dirichlet(null))\n",
    "draw_pdf_contours(ax[2], Dirichlet(actual))\n",
    "draw_pdf_contours(ax[3], Dirichlet(previous))\n",
    "ax[0].set_title('Prior')\n",
    "ax[1].set_title('Null posterior')\n",
    "ax[2].set_title('Our posterior')\n",
    "ax[3].set_title('Previous study posterior')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd6817",
   "metadata": {},
   "source": [
    "#### Tail probabilities (Quoted from BDA3, pg 146)\n",
    "\"We can evaluate the fit of the null and previous study posterior predictive distribution our data by considering the Bayesian {$p$}-value---the probability that data replicated from the posterior could be more extreme than the observed data, as measured by the test quantity\":\n",
    "\n",
    "${p}_B = \\text{Pr}(T(y^{rep}, \\theta)) \\ge T(y,\\theta)|y),$\n",
    "\n",
    "\"where the probability is taken over the posterior distribution of $\\theta$ and the posterior predictive distribution of $y^{rep}$. This is equivalent to the joint distribution, $p(\\theta, y^{rep}|y)$\":\n",
    "\n",
    "$p_B = \\int \\int I_{T(y^{rep},\\theta) \\ge T(y, \\theta)}p(y^{rep}|\\theta)p(\\theta|y)dy^{rep}d\\theta$.\n",
    "\n",
    "N.B. A test quantity $T(\\theta, y)$ generalizes the classical idea of a test statistic, $T(y)$; the difference being the quantity is also a function of the parameter values, $\\theta$.\n",
    "\n",
    "The first test quantity is the proportion of subjects exhibiting non-independence, $\\frac{N_{max} + N_{min}}{N}$.\n",
    "\n",
    "We can approximate this interval using Monte Carlo to first draw a parameter, $\\tilde{\\theta}$, then an artificial sample $y^{rep}|\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40e936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 1000\n",
    "\n",
    "def t(data):\n",
    "    return (data[0] + data[-1]) / np.sum(data)\n",
    "\n",
    "t_obs = t(actual - prior)\n",
    "print('t_obs is: {}'.format(t_obs))\n",
    "\n",
    "def tail_probs(model, t_obs, N, S=10000):\n",
    "    scores = 0\n",
    "    for s in np.arange(S):\n",
    "        params = np.random.dirichlet(model)\n",
    "        rep = np.random.multinomial(N, params)\n",
    "        t_rep = t(rep)\n",
    "        if t_rep > t_obs:\n",
    "            scores += 1\n",
    "    return scores/S\n",
    " \n",
    "modelNames = ['prior', 'null', 'previous', 'alpha']\n",
    "models = [prior, null, previous, alphaModel]\n",
    "\n",
    "for model_name, model in zip(modelNames, models):\n",
    "    p = tail_probs(model, t_obs, N)\n",
    "    print('For model <{}>, Bayesian p-value is {}.'.format(model_name, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0ff5ba",
   "metadata": {},
   "source": [
    "#### Bayes factors\n",
    "We can also compare models---in this case, the realistic null model and the full Dirichlet---by Bayesian model selection / comparison. This involves calculating or approximating the model evidence term, $p(D|M) = \\int_{\\theta'}p(D|\\theta', M)p(\\theta'|M)$.\n",
    "\n",
    "Adding a prior, our realistic null model is as follows:\n",
    "\n",
    "$$\n",
    "p(D|\\alpha) \\sim \\text{Multinomial}(N, \\alpha, 1-2\\alpha, \\alpha)\\\\\n",
    "p(\\alpha) \\sim \\text{Uniform}(0, 0.5)\n",
    "$$\n",
    "\n",
    "We wish to test whether the data are better accounted for by a unconstrained Dirichlet-Multinomial model. For instance, the null model cannot account for the asymmetry between MAX and MIN responses seen in our data and the original study. \n",
    "\n",
    "We can specify this model as follows:\n",
    "\n",
    "$$\n",
    "p(D|\\alpha) \\sim \\text{Multinomial}(N, {\\bf \\theta})\\\\\n",
    "p({\\bf \\theta}) \\sim \\text{Dirichlet}(1, 1, 1)\n",
    "$$\n",
    "\n",
    "Because the parameter space is small, it is likely we can reasonably approximate this integral using simple Monte Carlo, as follows:\n",
    "\n",
    "$$\n",
    "p(D|M) = \\int_{\\theta'}p(D|\\theta', M)p(\\theta'|M) \\approx \\frac{1}{J}\\sum_{j=1}^J p(D|\\theta^{(j)})\\\\\n",
    "\\theta^{(j)} \\sim p(\\theta) \n",
    "$$\n",
    "\n",
    "Assuming equal values for priors $p(M)$, we can compare the two models by the ratio of their evidence (Bayes Factor):\n",
    "\n",
    "$$\n",
    "\\text{BF} = \\frac{p(D|Full)}{p(D|Null)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f58f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evidence_MC(counts, param_fn, hyperparams, likelihood_fn, samples):\n",
    "    l = 0\n",
    "    for j in np.arange(samples):\n",
    "        params = param_fn(hyperparams)\n",
    "        l += likelihood_fn(counts, params)\n",
    "    return l / samples\n",
    "\n",
    "def theta_fn(dirichletParams):\n",
    "    \"\"\"Dirichlet params must have k length\"\"\"\n",
    "    theta = np.random.dirichlet(dirichletParams, size=None)\n",
    "    return theta\n",
    "\n",
    "def alpha_fn(alphaParams):\n",
    "    \"\"\"Alpha params must have 2 length\"\"\"\n",
    "    alpha = np.random.uniform(low=alphaParams[0], high=alphaParams[1])\n",
    "    return alpha\n",
    "\n",
    "def return_alpha_theta(alphaParams):\n",
    "    alpha = alpha_fn(alphaParams)\n",
    "    assert 0 <= alpha <= 0.5, \"alpha value wrong ({}): should be between 0 and 0.5\".format(alpha)\n",
    "    dP = np.array([alpha, 1-(2*alpha), alpha])\n",
    "    return theta_fn(dP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2836b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 10000\n",
    "MFull = evidence_MC(counts, theta_fn, [1, 1, 1], multinomial_probability, samples=J)\n",
    "MNull = evidence_MC(counts, return_alpha_theta, [0, 0.5], multinomial_probability, samples=J)\n",
    "print('Bayes Factor is: {}'.format(MFull / MNull))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863da7f1",
   "metadata": {},
   "source": [
    "## Weak Evidence 1: (D - B) - (C - A) greater than zero\n",
    "The authors of the original work mainly analyze differences of means. Although I have misgivings about this (see below), we can reconduct their original analysis.\n",
    "\n",
    "First, the authors examine whether (D - B) - (C - A) is positive and significantly greater than zero for each and all datasets. As we only have one, we will concentrate there. Although not explicitly stated, we assume they use a t-test for this.\n",
    "\n",
    "Recall that Student's t-test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6935cc47",
   "metadata": {},
   "source": [
    "\"The reason that this is only weak support for MAX is that it falls short\n",
    "of the ordinal effect that was required for MAX support in Experiments 1\n",
    "and 2. The above results could be explained without invoking MAX; for\n",
    "example, it could be that subjects similarity judgments are more sensitive\n",
    "in the 5-6 range than they are in the 67 range. That is, the rating scale\n",
    "may not satisfy the assumptions of an interval scale. So, the difference\n",
    "between 5.6 and 5.8 may be psychologically equal to the difference between\n",
    "6.0 and 6.8.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
